# ── AllKnower Environment Variables ──────────────────────────────────────────

# Server
PORT=3001
NODE_ENV=development

# PostgreSQL (via Prisma)
DATABASE_URL=postgresql://user:password@localhost:5432/allknower

# better-auth
BETTER_AUTH_SECRET=...
BETTER_AUTH_URL=http://localhost:3001

# OpenRouter
OPENROUTER_API_KEY=sk-or-...
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# LLM Models (routed through OpenRouter)
BRAIN_DUMP_MODEL=x-ai/grok-4.1-fast
CONSISTENCY_MODEL=moonshotai/kimi-k2.5

# Embedding Models
# EMBEDDING_LOCAL: used when Ollama is available (local, zero cloud cost)
# EMBEDDING_CLOUD: fallback when Ollama is unreachable
EMBEDDING_LOCAL=ollama/nomic-embed-text
EMBEDDING_CLOUD=google/gemini-embedding-001

# Ollama (local embeddings)
OLLAMA_BASE_URL=http://localhost:11434

# LanceDB (embedded — path to local DB directory)
LANCEDB_PATH=./data/lancedb

# AllCodex ETAPI (Trilium REST API)
ALLCODEX_URL=http://localhost:8080
ALLCODEX_ETAPI_TOKEN=your-etapi-token-from-allcodex-settings

# Rate limiting
BRAIN_DUMP_RATE_LIMIT_MAX=10
BRAIN_DUMP_RATE_LIMIT_WINDOW_MS=60000
